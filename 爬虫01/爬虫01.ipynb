{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install lxml\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "目标爬取百度学术的论文标题、引用数、发表年份\n",
    "先分解任务，从单页内容开始\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://xueshu.baidu.com/s?wd=resnet&rsv_bp=0&tn=SE_baiduxueshu_c1gjeupa&rsv_spt=3&ie=utf-8&f=8&rsv_sug2=0&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D'\n",
    "strhtml=requests.get(url)\n",
    "soup=BeautifulSoup(strhtml.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup, sel):\n",
    "    title = soup.select(sel)\n",
    "    if len(title) > 0:\n",
    "        title_d = title[0].get_text()\n",
    "        return title_d\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_count(soup, sel):\n",
    "    count = soup.select(sel)\n",
    "    # 排除下面2种情况时，引用数为0\n",
    "    if len(count) == 0:\n",
    "        return 0\n",
    "    count_d = count[0].get_text()\n",
    "    count_d = re.findall(r'\\d+', count_d)\n",
    "    if len(count_d) > 0:\n",
    "        return count_d[0]\n",
    "    sel = sel.replace('span:nth-child(2)', 'span:nth-child(3)')\n",
    "    count = soup.select(sel)\n",
    "    count_d = count[0].get_text()\n",
    "    count_d = re.findall(r'\\d+', count_d)\n",
    "    return count_d[0]\n",
    "    \n",
    "\n",
    "def get_year(soup, sel):\n",
    "    year = soup.select(sel)\n",
    "    # 存在没有年份的情况\n",
    "    if len(year) == 0:\n",
    "        return -1\n",
    "    year_d = year[0].get('data-year')\n",
    "    return year_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\n",
      "1495\n",
      "2016\n",
      "Wider or Deeper: Revisiting the ResNet Model for Visual Recognition\n",
      "117\n",
      "2016\n",
      "Brazilian Network for HIV Drug Resistance Surveillance (HIV-BResNet): a new survey of HIV recent diagnosed individuals collected in ...\n",
      "119\n",
      "2009\n",
      "VoxResNet: Deep voxelwise residual networks for brain segmentation from 3D MR images - ScienceDirect\n",
      "64\n",
      "2018\n",
      "Kinetic of the NO removal by nonthermal plasma in N2/NO/C2H4 mixtures\n",
      "75\n",
      "2000\n",
      "In Vitro Transcription of the Viral-Specific Sequences Presnet in the Chromatin of Cells Transformed by Simian Virus 40\n",
      "43\n",
      "1973\n",
      "Secondary Mediation and Regression Analyses of the PTClinResNet Database: Determining Causal Relationships Among the International C...\n",
      "22\n",
      "2011\n",
      "Linking trait variation to the environment\n",
      "13\n",
      "2017\n",
      "Act to staunch loss of research data\n",
      "13\n",
      "2015\n",
      "Study of Ammonia Formation During the Purge of a Lean NO\n",
      "11\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "tmp = [str(i)+' ' for i in range(31, 40)]\n",
    "tmp.append('31 0')\n",
    "for i in tmp:\n",
    "    sel0 = '#\\\\{} > div.sc_content > h3 > a'.format(i)\n",
    "    title = get_title(sel0)\n",
    "    print(title)\n",
    "    sel1 = '#\\\\{} > div.sc_content > div.sc_info > span:nth-child(2) > a'.format(i)\n",
    "    count = get_count(sel1)\n",
    "    print(count)\n",
    "    sel2 = '#\\\\{} > div.sc_content > div.sc_info > span.sc_time'.format(i)\n",
    "    year = get_year(sel2)\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "上个单元，告一段落，可以适当休息一下\n",
    "接下来爬取多页结果\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(n):\n",
    "    s = '3' + str(n)\n",
    "    if len(s) > 2:\n",
    "        s = s[:2] + ' ' + s[2:]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "counts = []\n",
    "years = []\n",
    "flag = True\n",
    "i = 0\n",
    "while flag:\n",
    "    url = 'https://xueshu.baidu.com/s?wd=resnet&pn={}&tn=SE_baiduxueshu_c1gjeupa&ie \\\n",
    "        =utf-8&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&sc_hit=1'.format(i)\n",
    "    strhtml=requests.get(url)\n",
    "    soup=BeautifulSoup(strhtml.text, 'lxml')\n",
    "    for j in range(1, 11):\n",
    "        tar = trans(i + j)\n",
    "        sel0 = '#\\\\{} > div.sc_content > h3 > a'.format(tar)\n",
    "        title = get_title(soup, sel0)\n",
    "        if title == None:\n",
    "            flag = False\n",
    "            break\n",
    "        titles.append(title)\n",
    "        sel1 = '#\\\\{} > div.sc_content > div.sc_info > span:nth-child(2) > a'.format(tar)\n",
    "        count = get_count(soup, sel1)\n",
    "        counts.append(count)\n",
    "        sel2 = '#\\\\{} > div.sc_content > div.sc_info > span.sc_time'.format(tar)\n",
    "        year = get_year(soup, sel2)\n",
    "        years.append(year)\n",
    "    i += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "counts = []\n",
    "years = []\n",
    "ckpt = 0\n",
    "def retry_scrape(ckpt):\n",
    "    # 增加重试功能，应对网络不稳定情况\n",
    "    i = ckpt // 10\n",
    "    last_j = ckpt % 10 + 1\n",
    "    while 1:\n",
    "        url = 'https://xueshu.baidu.com/s?wd=resnet&pn={}&tn=SE_baiduxueshu_c1gjeupa&ie \\\n",
    "            =utf-8&sc_f_para=sc_tasktype%3D%7BfirstSimpleSearch%7D&sc_hit=1'.format(i)\n",
    "        strhtml=requests.get(url)\n",
    "        soup=BeautifulSoup(strhtml.text, 'lxml')\n",
    "        for j in range(last_j, 11):\n",
    "            tar = trans(i + j)\n",
    "            sel0 = '#\\\\{} > div.sc_content > h3 > a'.format(tar)\n",
    "            title = get_title(soup, sel0)\n",
    "            if title == None:\n",
    "                return i + j\n",
    "            titles.append(title)\n",
    "            sel1 = '#\\\\{} > div.sc_content > div.sc_info > span:nth-child(2) > a'.format(tar)\n",
    "            count = get_count(soup, sel1)\n",
    "            counts.append(count)\n",
    "            sel2 = '#\\\\{} > div.sc_content > div.sc_info > span.sc_time'.format(tar)\n",
    "            year = get_year(soup, sel2)\n",
    "            years.append(year)\n",
    "        last_j = 1\n",
    "        i += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = retry_scrape(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "将结果保存为excel文件\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install XlsxWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {  \n",
    "    '文章': titles,  \n",
    "    '引用数': counts,\n",
    "    '发表时间': years\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将字典转换为DataFrame  \n",
    "df = pd.DataFrame(data)  \n",
    "  \n",
    "# 创建一个ExcelWriter对象，你可以选择一个文件名或者一个已经打开的文件对象  \n",
    "writer = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')  \n",
    "  \n",
    "# 将DataFrame写入到Excel文件的一个sheet中  \n",
    "df.to_excel(writer, sheet_name='Sheet1', index=False)  \n",
    "\n",
    "# 关闭ExcelWriter对象，这时会触发将数据写入到Excel文件中  \n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
